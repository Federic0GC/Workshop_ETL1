{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fbe799b",
   "metadata": {},
   "source": [
    "# Workshop_1_Analysis\n",
    "- This jupyter deals with all the work requested from the workshop_1, loading and connecting to the database, in addition to the cloning of the original dataframe with the new Hired solicidate field.\n",
    "- in addition to this whole process, this notebook includes a more in-depth analysis of the dataset with the new field requested, remember that although if SQL queries were made all these were made only for the above mentioned process since the analysis works with the new table brought from the database and saved as a dataframe (the analysis made later was not working with any SQL query)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc3b3de",
   "metadata": {},
   "source": [
    "# Import of libraries\n",
    "- It is important to emphasize that environment variables are being handled as good practice and these variabes are saved in a file . env in the gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de160bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f808f0b",
   "metadata": {},
   "source": [
    "# Loading and handling of environment variables\n",
    "- We use environment variables with a file. env as good practice in handling credentials in the main file that does the whole process (as is the case with this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ece29",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bdce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user = os.getenv(\"DB_USER\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_database = os.getenv(\"DB_DATABASE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb707c3",
   "metadata": {},
   "source": [
    "# CSV reading and general exploration\n",
    "### This general analysis which returns the information of each field and some of the records of our table, allows us to identify fundamental characteristics to our future analysis and process\n",
    "- From this small first approach we can realize things like that the field of the day of application of the candidature is an object, format that makes it difficult for us to visualize, analyze and plot more in depth all the material that offers us a complete date (Year, month, day) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4bf9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = '../Data/candidates.csv' \n",
    "candidates_df = pd.read_csv(candidates, delimiter=';') \n",
    "print(candidates_df.head())\n",
    "print(candidates_df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a3e5c",
   "metadata": {},
   "source": [
    "# Connection to MySQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Workshop_1_mysql_connection = pymysql.connect(db=db_database, user=db_user, passwd=db_password)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6aa0dc",
   "metadata": {},
   "source": [
    "# Loading the data and the candidates table to the database\n",
    "- After reading and creating the connection with our database we proceed to upload the data from our table to the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    Workshop_1_mysql_connection_str = f'mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_database}'\n",
    "\n",
    "    Workshop_1_mysql_db_connection = create_engine(Workshop_1_mysql_connection_str)\n",
    "    print(\"Connection made to the database...\")\n",
    "\n",
    "    candidates_df.to_sql('candidates', con=Workshop_1_mysql_db_connection, index=False, if_exists='replace')\n",
    "    print(\"Data loaded correctly in the 'candidates' table'\")\n",
    "    print(\"Check if the table was successfully added to your database (MySQL)\")\n",
    "\n",
    "except pymysql.Error as e:\n",
    "    \n",
    "    print(f\"Failed to connect to MYSQL database: {e}\")\n",
    "\n",
    "finally:\n",
    "    \n",
    "    if 'workshop_1_mysql_db_connection' in locals():\n",
    "        Workshop_1_mysql_db_connection.dispose()\n",
    "    print(\"Data connection and upload done correctly, connection closed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683e0dc",
   "metadata": {},
   "source": [
    "# A new dataframe is created which is a copy of the original table with a new hired field \n",
    "\n",
    "- Throughout the code the number of individual records that comply with each restriction is also analyzed, such as the request to the database of total tables to confirm the creation of the latter\n",
    "- If the field of code_challeng and tecnical_interview has a value greater than or equal to 7 in its register this shall be considered as an approved register having a Yes in the hired field\n",
    "- If, on the other hand, the registration does not meet one or all of these requirements in these two different fields, it will not be considered approved and will have a No in the hired field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "Workshop_querys_mysql_connection = pymysql.connect(db=db_database, user=db_user, passwd=db_password)\n",
    "\n",
    "try:\n",
    "    Workshop_querys_mysql_connection_str = f'mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_database}'\n",
    "    Workshop_querys_mysql_db_connection = create_engine(Workshop_querys_mysql_connection_str)\n",
    "\n",
    "    candidates_select_all_data_sql_query = \"SELECT * FROM candidates\"\n",
    "    candidates_df = pd.read_sql_query(candidates_select_all_data_sql_query, Workshop_querys_mysql_db_connection)\n",
    "\n",
    "    candidates_df['Hired'] = candidates_df.apply(lambda row: 'Yes' if row['Technical Interview Score'] >= 7 and row['Code Challenge Score'] >= 7 else 'No', axis=1)\n",
    "\n",
    "    code_challenge_aprobados_df = candidates_df[candidates_df['Code Challenge Score'] >= 7] \n",
    "    print(f\"Number of records with Code Challenge Score >= 7: {len(code_challenge_aprobados_df)}\")\n",
    "\n",
    "    technical_interview_aprobados_df = candidates_df[candidates_df['Technical Interview Score'] >= 7] \n",
    "    print(f\"Number of records with Technical Interview Score >= 7: {len(technical_interview_aprobados_df)}\")\n",
    "\n",
    "    candidates_show_tables_sql_query = \"SHOW TABLES;\"\n",
    "    tabla_df = pd.read_sql_query(candidates_show_tables_sql_query, Workshop_querys_mysql_db_connection)\n",
    "    print(\"These are the tables that the database has right now:\")\n",
    "    print(tabla_df)\n",
    "\n",
    "    candidates_hired = 'candidates_hired'\n",
    "    candidates_df.to_sql(candidates_hired, Workshop_querys_mysql_db_connection, index=False, if_exists='replace')\n",
    "\n",
    "    print(f\"Data loaded correctly in the table '{candidates_hired}'.\")\n",
    "\n",
    "    sql_query_hired = f\"SELECT * FROM {candidates_hired}\"\n",
    "    candidates_hired_df = pd.read_sql_query(sql_query_hired, Workshop_querys_mysql_db_connection)\n",
    "    print(\"New DataFrame with the 'Hired' field:\")\n",
    "    print(candidates_hired_df.head())\n",
    "\n",
    "except pymysql.Error as e:\n",
    "    print(f\"Failed to connect to MYSQL database: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'Workshop_querys_mysql_db_connection' in locals():\n",
    "        Workshop_querys_mysql_db_connection.dispose()\n",
    "        print(\"Creation of the new table with the field 'Hired', and other queries performed successfully, closing the new connection...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7836d43e",
   "metadata": {},
   "source": [
    "## We confirm that the new dataset complies with the new field and its restrictions\n",
    "### As we can the table with its new field 'Hired' was created and uploaded to the database correctly\n",
    "- What we are doing here in future is to handle the new dataframe that we did everything with pandas\n",
    "- We see how the field 'Hired' successfully complies with the restrictions that we put it being the register 2 and 3 that at first glance make us realize this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(candidates_hired_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb96ec7e",
   "metadata": {},
   "source": [
    "# Number of records that do not meet the restrictions in the new field\n",
    "- We do this to take a step by step of what will be an analysis on these approved and not approved records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f015d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_no_hired_registers = candidates_hired_df[candidates_hired_df['Hired'] == 'No'].shape[0]\n",
    "print(f\"Total records that do not meet the requirements for hiring: {Total_no_hired_registers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f3d49",
   "metadata": {},
   "source": [
    "# Number of records that meet the restrictions of the new field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef117b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_yes_hired_registers = candidates_hired_df[candidates_hired_df['Hired'] == 'Yes'].shape[0]\n",
    "print(f\"Total records that meet the requirements for hiring: {Total_yes_hired_registers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4833550",
   "metadata": {},
   "source": [
    "# Display of records by hired field\n",
    "- With this graphic we can give an idea of the difference between the candidates who were approved and those who were not in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e237c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_Hired = candidates_hired_df['Hired'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "Total_Hired.plot(kind='bar', color=['blue', 'red'])\n",
    "plt.title('Number of Records with \"Hired\" Field')\n",
    "plt.xlabel('Hired')\n",
    "plt.ylabel('Number of records')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de7780",
   "metadata": {},
   "source": [
    "# Analysis of the percentage of hires who were hired according to the new dataframe\n",
    "- It is interesting to see how many total records only 13.40% of all those records met the requirements to be hired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bb7cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Registers_Hired = len(candidates_hired_df[candidates_hired_df['Hired'] == 'Yes'])\n",
    "\n",
    "Total_of_registers = len(candidates_hired_df)\n",
    "\n",
    "Rate_of_registers = (Registers_Hired  / Total_of_registers) * 100\n",
    "\n",
    "print(f\"Percentage of employees: {Rate_of_registers:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8bf4f",
   "metadata": {},
   "source": [
    "# Pastel graphic\n",
    "\n",
    "- We do this graph with a proposition and is to be able to visualize the totality of candidates that were not approved, against which we now know are the other 13.40% candidates that we know if they were approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_of_hires = candidates_hired_df['Hired'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(Number_of_hires, labels=Number_of_hires.index, autopct='%1.1f%%', colors=['pink', 'purple'])\n",
    "\n",
    "plt.title('Percentage of Candidates Recruited')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dcff82",
   "metadata": {},
   "source": [
    "# Analysis first approach to what will be the dashboard of our Workshop\n",
    "- the graphs that you will see are made in order to be able to compare them with the orders explicitly in the dashboard of the job, being able to understand them better and already go with certain conclusions of how some data will tend to behave when making our dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa1f527",
   "metadata": {},
   "source": [
    "# Technology approved number graphic bar\n",
    "- This graph allows us to see a trend between two technologies called \"Game development\" and \"Dep Ops\" which are the most accepted in our dataset, while the others follow a not so large number of records between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76800cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hired_by_tecnology = candidates_hired_df.groupby('Technology')['Hired'].count().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "Hired_by_tecnology.plot(kind='bar', color='lightgreen')\n",
    "plt.title('Number of Employees by Technology')\n",
    "plt.xlabel('Technology')\n",
    "plt.ylabel('Number of recruitments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a5a32",
   "metadata": {},
   "source": [
    "# Graphic of the number of contracts by the countries requested in the workshop\n",
    "\n",
    "- This style of graphics allows us to see the total number of hires that each country had, while what can be seen in the dashboard is also analyzed a behavior taking into account the years\n",
    "- Although the graph that we will see in the dashboard is over the years, this helps us to know which country is the most contracted, and the total of each country, knowing that the sum of each contracted over the years must give us the total that we see here of each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a55e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Specific_countries = ['Brazil', 'Colombia', 'Ecuador', 'United States of America']\n",
    "Filtered_df = candidates_hired_df[candidates_hired_df['Country'].isin(Specific_countries)]\n",
    "\n",
    "Hired_by_country_total_counts = Filtered_df[Filtered_df['Hired'] == 'Yes'].groupby('Country').size()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=Hired_by_country_total_counts.index, y=Hired_by_country_total_counts.values, color='skyblue')\n",
    "plt.title('Number of hires by Country')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Number of hires')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b43e1",
   "metadata": {},
   "source": [
    "# Graph of the number of contracts for each year of the dataset\n",
    "- This graph allows us to see how a year in specicio (2022) brings with it the year with fewer hires by far, this data is very important when we seek to see and analyze different data per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a8f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_hired_df['Application Date'] = pd.to_datetime(candidates_hired_df['Application Date'])\n",
    "\n",
    "Filtered_years_2018_to_2019_df = candidates_hired_df[(candidates_hired_df['Application Date'].dt.year >= 2018) & (candidates_hired_df['Application Date'].dt.year <= 2022)]\n",
    "\n",
    "Hired_by_year_counts = Filtered_years_2018_to_2019_df[Filtered_years_2018_to_2019_df['Hired'] == 'Yes'].groupby(Filtered_years_2018_to_2019_df['Application Date'].dt.year).size()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=Hired_by_year_counts.index, y=Hired_by_year_counts.values, color='lightgreen')\n",
    "plt.title('NÃºmber of hires by Year (2018-2022)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of hires')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d30b74",
   "metadata": {},
   "source": [
    "# Pie chart of the distribution of contract by Seniority\n",
    "- This graph allows us to visualize that Seniority was the one that most contracted in general, also realize that it is not excatmanete a \"perfect\" distribution there is no Seniority that has been delayed by a very high percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5d9326",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Hired_by_seniority_counts = candidates_hired_df[candidates_hired_df['Hired'] == 'Yes']['Seniority'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(Hired_by_seniority_counts, labels=Hired_by_seniority_counts.index, autopct='%1.1f%%', colors=sns.color_palette('pastel'), startangle=140)\n",
    "plt.title('Distribution of Hires by Seniority')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
